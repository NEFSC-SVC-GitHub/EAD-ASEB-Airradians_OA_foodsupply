::::::::::::::::::::::::::::::::::::::
library(devtools) # devtools::install_github # use devtools to instlal github link
library(LoLinR) # install_github('colin-olito/LoLinR') # install LoLinR from github
library(dplyr)
library(lubridate)
library(rMR)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_OA/RAnalysis")
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER ::::::::::::::::::::::
path.p    <- "Data/Respiration" #the location of all your respirometry files
a         <- 0.4
ouputNAME <- "Output/Respiration/Cumulative_resp_alpha0.4.csv"
# ANALYSIS  :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Objective: use LoLinr to run all respiration rates in a non-bias and autonomous fashion
# Ouputs: there will be two main resources from this script:
#   (1) cumulative spreasheet of all respiration rate value for each Channel on each day
#   (2) a folder of plots from the LoLinR script to a plots folder - this will allow troubleshooting and sanity checks
# I. call subfolders as dataframe and create a dataframe for the output
# call the subfolder names for the outside loop 'i' (i.e. 20210914)
folder.names           <- basename(list.files(path = path.p, pattern = "", recursive = FALSE)) #list all csv file names in the folder and subfolders
folder.names.table     <- data.frame(folder.names)
# Call the cumulative dataframe that we will write to in the for loop below
df_total             <- data.frame() # start dataframe
resp.table           <- data.frame(matrix(nrow = 1, ncol = 7)) # create dataframe to save cumunalitively during for loop
colnames(resp.table) <- c('Date', 'Channel', 'Lpc', 'Leq' , 'Lz', 'alpha','Filename') # names for comuns in the for loop
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[1,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[2,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
Resp.Data           <- read.delim2(file = paste(path.p,'/',folder.names.table[2,1], '/', file.names.table[2,1], sep=''), header = TRUE,skip = 37) #reads in the data files
folder.names.table     <- data.frame(folder.names)
folder.names.table
Resp.Data           <- read.delim2(file = paste(path.p,'/',folder.names.table[2,1], '/', file.names.table[1,1], sep=''), header = TRUE,skip = 37) #reads in the data files
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[2,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
Resp.Data           <- read.delim2(file = paste(path.p,'/',folder.names.table[2,1], '/', file.names.table[1,1], sep=''), header = TRUE,skip = 37) #reads in the data files
file.names.table[1,1]
folder.names.table     <- data.frame(folder.names)
folder.names.table
file.names.table[1,1]
nrow(file.names.table)
file.names.table
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[2,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table
nrow(folder.names.table)
folder.names.table
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[1,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
Resp.Data           <- read.delim2(file = paste(path.p,'/',folder.names.table[1,1], '/', file.names.table[1,1], sep=''), header = TRUE,skip = 37) #reads in the data files
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
#dplyr::filter(!Phase %in% 'Flush') %>% # remove the initial rows labeled flush
dplyr::select(c(date, seconds, minutes, contains(".O2...air.sat"))) # call unique column names for the 8 Channels
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,3) # clean these column names to make things easier - first 3 characters
# Truncate! EVERY 30 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recoreded values every second, this slows the model dramatically with >2000 values for each Channel, call every 30 seconds to speed this up
# discuss with collaborators on this truncated approach
Resp.Data_30sec = Resp.Data[seq(1, nrow(Resp.Data), 30), ]
Resp.Data_30sec
# Truncate! EVERY 30 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recoreded values every second, this slows the model dramatically with >2000 values for each Channel, call every 30 seconds to speed this up
# discuss with collaborators on this truncated approach
Resp.Data_30sec = Resp.Data[seq(1, nrow(Resp.Data), 30), ] %>% dplyr::(!minutes > 40)
# Truncate! EVERY 30 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recoreded values every second, this slows the model dramatically with >2000 values for each Channel, call every 30 seconds to speed this up
# discuss with collaborators on this truncated approach
Resp.Data_30sec = Resp.Data[seq(1, nrow(Resp.Data), 30), ] %>% dplyr::filter(!minutes > 40)
Resp.Data_30sec
# outside 'i' loop - call each subfolder one at a time for analysis
for(i in 1:nrow(folder.names.table)) { # for every subfolder 'i' ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# call all txt files labelled 'raw' in each subfolder (i.e. 20210914) and create a table
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
# inside 'm' loop - call each 'raw' .txt file wihtin the subfolder 'i'
for(m in 1:nrow(file.names.table)) { # for every 'raw' .txt file 'm' in the subfolder 'i' :::::::::::::::::::::::::::::::::::::
Resp.Data           <- read.delim2(file = paste(path.p,'/',folder.names.table[i,1], '/', file.names.table[m,1], sep=''), header = TRUE,skip = 37) #reads in the data files
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
#dplyr::filter(!Phase %in% 'Flush') %>% # remove the initial rows labeled flush
dplyr::select(c(date, seconds, minutes, contains(".O2...air.sat"))) # call unique column names for the 8 Channels
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,3) # clean these column names to make things easier - first 3 characters
# Truncate! EVERY 30 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recoreded values every second, this slows the model dramatically with >2000 values for each Channel, call every 30 seconds to speed this up
# discuss with collaborators on this truncated approach
Resp.Data_30sec = Resp.Data[seq(1, nrow(Resp.Data), 30), ] %>% dplyr::filter(!minutes > 40)
# inside 'j' loop - for each 'raw' txt file 'm', call each O2 sensor/resp chamber 'j' for analysis
for(j in 4:(ncol(Resp.Data_30sec))){ # for each sensor column 'j' (..starting at column 4) :::::::::::::::::::::::::::::::
Resp_loop         <- na.omit(Resp.Data_30sec[,c(3,j)]) # noticed some random rows have 'NaN' - so I will loop the min and Channels to ommit Nas before proceeding
Resp_loop$mgL     <- DO.unit.convert(as.numeric(Resp_loop[,2]),  # DO in percent air sat to be converted to mgL - uses an R package from loligo rMR
DO.units.in = "pct", DO.units.out ="mg/L",
bar.units.in = "kPa", bar.press = barromP_kPa, bar.units.out = "kpa",
temp.C = temperature_C,
salinity.units = "pp.thou", salinity = salinity.pp.thou)
if (nrow(Resp_loop) < 1) { # if column 'j' is NA write NA in the cumulative sheet...
resp.table$Date                <- Resp.Data_30sec[1,1]
resp.table$Channel             <- colnames(Resp_loop)[2]
resp.table[3:ncol(resp.table)] <- 'NA'
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
} else { # else run LoLinR for x=mins and y=mg/l O2
model <- rankLocReg(
xall    = as.numeric(Resp_loop[, 1]),
yall    = as.numeric(Resp_loop[, 3]), # call x as the minute timeseries and y as the % air saturation of the particular Channel
alpha   = a,  # alpha was assigned earlier as 0.4 by the authors default suggestions - review Olito et al. and their github page for details
method  = "pc",
verbose = TRUE)
sum.table <- summary(model)
resp.table$Date       <- Resp.Data_30sec[1,1]
resp.table$Channel    <- colnames(Resp_loop)[2]
resp.table$Lpc        <- sum.table$Lcompare[3,6] # Lpc slope - call the column 'b1'
resp.table$Leq        <- sum.table$Lcompare[2,6] # Leq slope - call the column 'b1'
resp.table$Lz         <- sum.table$Lcompare[1,6] # Lz slope  - call the column 'b1'
resp.table$alpha      <- a
resp.table$Filename   <- file.names.table[m,1]
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm30sec/trunc40minutes/",folder.names.table[i,1],"_", sub("_raw.*","",file.names.table[m,1]),"_",colnames(Resp_loop)[2],"_regression.pdf"))
plot(model)
dev.off()
} # end of  else statement (if column 'j' is NA write NA in the cumulative sheet, else run LoLinR for x=mins and y = mg/l O2)
} # end of inside for loop 'j' (for each sensor column 'j' [a] isolate mins and CH_ for analysis [b] convert CH_ data to mg/L using 'DO.unit.convert' [c] calc respi rates with LoLin R)
} # end of inside  for loop 'm' (for every 'raw' .txt file 'm' in the subfolder 'i')
} # end of outside for loop 'i' (for every subfolder 'i')
df_total
ouputNAME <- "Output/Respiration/Cumulative_resp_alpha0.4_trunc40mins.csv"
# merge with the preexisiting table
# NOTE: raw values here are...
# (1) in units of mg/L min-1 (slope of line mg/l / mins in LoLinR - check the plot outputs to see)
# (2) not normalized for volume chamber
# (3) not normalized for blank resp rate
# (4) not normalized for a size/individual metric
cumulative_resp_table <- read.csv(file=ouputNAME, header=TRUE) #call the pre existing cumulative table
new_table             <- rbind(cumulative_resp_table, df_total) # bind the new table from the for loop to the pre exisiting table
write.table(new_table,ouputNAME,sep=",", row.names=FALSE)  # write out to the path names outputNAME
# merge with the preexisiting table
# NOTE: raw values here are...
# (1) in units of mg/L min-1 (slope of line mg/l / mins in LoLinR - check the plot outputs to see)
# (2) not normalized for volume chamber
# (3) not normalized for blank resp rate
# (4) not normalized for a size/individual metric
cumulative_resp_table <- read.csv(file=ouputNAME, header=TRUE) #call the pre existing cumulative table
new_table             <- rbind(cumulative_resp_table, df_total) # bind the new table from the for loop to the pre exisiting table
write.table(new_table,ouputNAME,sep=",", row.names=FALSE)  # write out to the path names outputNAME
cumulative_resp_table
df_total
library(dplyr)
library(ggplot2)
library(forcats)
library(lmer4)
library(lmerTest)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_OA/RAnalysis") #
# LOAD DATA :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
resp.data    <- read.csv(file="Output/Respiration/Cumulative_resp_alpha0.4_trunc40mins.csv", header=T) %>% dplyr::filter(!Filename %in% 'Run_1_raw.txt') # read the calculate raw rates from 'resp_LoLin' script - contains the calculated rate (not normalized for blanks) for each sensor-channel
exp_metadata <- read.csv(file="Data/ExperimentMetadata.csv", header=T) # treatment assignments to 'Chamber_Tank'
lengths      <- read.csv(file="Data/Lengths_resp.csv", header=T) %>%
dplyr::select(c('Run','Chamber_tank', 'Length.um.'))
resp.ref     <- read.csv(file="Data/Respiration/Reference_master.csv", header=T) %>%
dplyr::filter(!Filename %in% 'Run_1_raw.txt') %>% # reference for the respirometry data - contains the 'Chamber_Tank' for each sensor channel (whether an animal or a blank)
dplyr::mutate(Run = gsub("[- .)_(+]|[a-zA-Z]*:?","", Filename))
# merge the exp_metadata with the resp.data
resp.ref_merged_1                 <- merge(exp_metadata, resp.ref, by = 'Chamber_tank', all=TRUE) # all TRUE allows us to keep the blanks
resp.ref_merged_2                 <- merge(resp.ref_merged_1, lengths, by = c('Run', 'Chamber_tank'), all=TRUE) # all TRUE allows us to keep the blanks
resp.data_merged                   <- merge(resp.data, resp.ref_merged_2, by = c('Date', 'Channel','Filename')) # out master file moving forward....
dates.runs <- resp.data_merged %>%  # call table
dplyr::distinct(Date, Filename) # call all unique values for date run and sw condition
dates.runs <- na.omit(dates.runs)
# call dataframe and build table to rbind in for loop
blanks_total <- data.frame() # start dataframe
blanks.table <- data.frame(matrix(nrow = 1,ncol = 5)) # make a table template
colnames(blanks.table)<-c('Date', 'Channel', 'mean_Lpc', 'mean_Leq' , 'mean_Lz') # names for comuns in the for loop
data <- resp.data_merged %>%
dplyr::select(Date, Chamber_tank, Filename, Channel, Lpc,  Leq, Lz) %>%
dplyr::filter(!is.na(Lpc)) # ommits empty resp channels (if any)
blanks <- data.frame(data %>%
dplyr::filter(! Filename %in% 'Run_1_raw.txt') %>% # run 1 on 9/14 was restarted - I assume to ommit the previous from analysis
dplyr::group_by(Channel, Date) %>%
dplyr::filter(Chamber_tank == "blank") %>%
dplyr::summarise(BLANK.mean_Lpc = mean(abs(Lpc)),
BLANK.mean_Leq = mean(abs(Leq)),
BLANK.mean_Lz = mean(abs(Lz))) %>%
dplyr::mutate(pCO2 = case_when(
Channel == "CH8" ~ "H",
Channel == "CH4"  ~ "L")))
blanks <- blanks %>% dplyr::select(!Channel) # ommit channel to reduce confusion when merged - treatment will be merged with the resp.data.merged' dataframe
Resp.Master <- merge(resp.data_merged, blanks, by=c("Date", "pCO2")) %>% # NOTE: this repeats for every distinct length value
dplyr::mutate(resp_norm = Lpc - BLANK.mean_Lpc) # ommits respiration rate values showing an increase in O2 over time
Resp.Master_OM <- Resp.Master %>% dplyr::filter(!resp_norm > 0) # ommit respiration values that are positive
# NOTE: look at the following table to troubleshoot if needed
Resp.outliers <- Resp.Master %>% dplyr::filter(resp_norm > 0) # call the values with positive resp rates, measing they were slower than the blank!
# calculate resp rates
vial.vol <- 0.8 # milliliters (ml) - to nomalize by volume (L)
Resp.Master_OM$resp_ug_L_hr <- ( (abs(Resp.Master_OM$resp_norm)*1000)* # convert mg/L to ug/L
(vial.vol/1000)* # normalize by volume
(60)) # convert per hour from per minute
Resp.Master_OM$resp_ng_L_umlLength_hr <- (
( ( (abs(Resp.Master_OM$resp_norm)*1000000) * # call absolute value of resp in mg per minute - convert to ng min-1
(vial.vol/1000) ) / # correct ng minute-1 to ng liter-1 by multiplying by the resp vial in liters
Resp.Master_OM$Length.um.) * # normalize by individual or larvae count - as to ng L-1 individual-1
(60)) # correct for the time; final value is ng Liter-1 individual-1 hour-1
# model effect of treatment on resp rate 20210507
Resp_0914 <- Resp.Master_OM %>%
dplyr::filter(Date %in% '9/14/2021') %>% # call only 9/14
dplyr::filter(!resp_ng_L_umlLength_hr >5) # ommit outliers
Resp_0914 %>% dplyr::group_by(Chamber_tank) %>% summarise(n()) # tank replication
LMmod_0914 <- aov(lm(resp_ng_L_umlLength_hr~pCO2,data=Resp_0914))
summary(LMmod_0914)
check_model(LMmod_0914) # observe the diagnostics of the model
shapiro.test(residuals(LMmod_0914)) # non normal
leveneTest(LMmod_0914) # good
MEmod_0914 <- lmer(resp_ng_L_umlLength_hr~pCO2 + (1|Chamber_tank),REML=TRUE, data=Resp_0914)
summary(MEmod_0914) # sig intercept just means the grand mean is different from 0 - not meaningful here..
check_model(MEmod_0914)
shapiro.test(residuals(MEmod_0914)) # non normal
leveneTest(MEmod_0914) # good
DF   <- paste( (summary(LMmod_0914)[[1]][["Df"]])[1], (summary(LMmod_0914)[[1]][["Df"]])[2], sep = '/')
Fval <- (summary(mod)[[1]][["F value"]])[1]
pval <- (summary(mod)[[1]][["Pr(>F)"]])[1]
ggplot(Resp_0914, aes(pCO2 , resp_ng_L_umlLength_hr , fill = pCO2)) +
theme(panel.grid=element_blank()) +
geom_boxplot(size=0.2, alpha=0.1, aes(fill=pCO2)) +
scale_fill_manual(values=c("grey50","white")) +
geom_point(shape = 21, size = 2, position = position_jitterdodge(jitter.width = 0.1)) +
theme_classic() +
scale_x_discrete(labels= c('Elevated (H)', 'Ambient (L)')) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold")) +
labs(title = "F1 Scallops: pediveliger respiration rates on 20210914",
y = expression(Respiration~rate~"("~ng~L^{-1}~O[2]%.%mu*m^{-1}%.% hr^{-1}~")"),
x = expression(italic(p)*CO[2]~Treatment~"("~mu*atm~")")) +
annotate("text", x=1.5, y=0.2, size = 4, label = "aov(Resp~Treatment + (1|Tank))") +
annotate("text", x=1.5, y=0.16, size = 4, label= paste('DF =',DF,'F =', signif(Fval, digits=3), 'p value =', signif(pval, digits=3), sep=" "))
library(dplyr)
library(ggplot2)
library(forcats)
library(lmer4)
library(lmerTest)
DF   <- paste( (summary(LMmod_0914)[[1]][["Df"]])[1], (summary(LMmod_0914)[[1]][["Df"]])[2], sep = '/')
Fval <- (summary(mod)[[1]][["F value"]])[1]
DF   <- paste( (summary(LMmod_0914)[[1]][["Df"]])[1], (summary(LMmod_0914)[[1]][["Df"]])[2], sep = '/')
Fval <- (summary(LMmod_0914)[[1]][["F value"]])[1]
pval <- (summary(LMmod_0914)[[1]][["Pr(>F)"]])[1]
ggplot(Resp_0914, aes(pCO2 , resp_ng_L_umlLength_hr , fill = pCO2)) +
theme(panel.grid=element_blank()) +
geom_boxplot(size=0.2, alpha=0.1, aes(fill=pCO2)) +
scale_fill_manual(values=c("grey50","white")) +
geom_point(shape = 21, size = 2, position = position_jitterdodge(jitter.width = 0.1)) +
theme_classic() +
scale_x_discrete(labels= c('Elevated (H)', 'Ambient (L)')) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold")) +
labs(title = "F1 Scallops: pediveliger respiration rates on 20210914",
y = expression(Respiration~rate~"("~ng~L^{-1}~O[2]%.%mu*m^{-1}%.% hr^{-1}~")"),
x = expression(italic(p)*CO[2]~Treatment~"("~mu*atm~")")) +
annotate("text", x=1.5, y=0.2, size = 4, label = "aov(Resp~Treatment + (1|Tank))") +
annotate("text", x=1.5, y=0.16, size = 4, label= paste('DF =',DF,'F =', signif(Fval, digits=3), 'p value =', signif(pval, digits=3), sep=" "))
Resp_0914 <- Resp.Master_OM %>%
dplyr::filter(Date %in% '9/14/2021')
Resp_0914 %>% dplyr::group_by(Chamber_tank) %>% summarise(n()) # tank replication
LMmod_0914 <- aov(lm(resp_ng_L_umlLength_hr~pCO2,data=Resp_0914))
summary(LMmod_0914)
check_model(LMmod_0914) # observe the diagnostics of the model
shapiro.test(residuals(LMmod_0914)) # non normal
leveneTest(LMmod_0914) # good
leveneTest(residuals(LMmod_0914)) # good
library(car)
leveneTest(LMmod_0914) # good
MEmod_0914 <- lmer(resp_ng_L_umlLength_hr~pCO2 + (1|Chamber_tank),REML=TRUE, data=Resp_0914)
summary(MEmod_0914) # sig intercept just means the grand mean is different from 0 - not meaningful here..
check_model(MEmod_0914)
shapiro.test(residuals(MEmod_0914)) # non normal
leveneTest(MEmod_0914) # good
DF   <- paste( (summary(LMmod_0914)[[1]][["Df"]])[1], (summary(LMmod_0914)[[1]][["Df"]])[2], sep = '/')
Fval <- (summary(LMmod_0914)[[1]][["F value"]])[1]
pval <- (summary(LMmod_0914)[[1]][["Pr(>F)"]])[1]
ggplot(Resp_0914, aes(pCO2 , resp_ng_L_umlLength_hr , fill = pCO2)) +
theme(panel.grid=element_blank()) +
geom_boxplot(size=0.2, alpha=0.1, aes(fill=pCO2)) +
scale_fill_manual(values=c("grey50","white")) +
geom_point(shape = 21, size = 2, position = position_jitterdodge(jitter.width = 0.1)) +
theme_classic() +
scale_x_discrete(labels= c('Elevated (H)', 'Ambient (L)')) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold")) +
labs(title = "F1 Scallops: pediveliger respiration rates on 20210914",
y = expression(Respiration~rate~"("~ng~L^{-1}~O[2]%.%mu*m^{-1}%.% hr^{-1}~")"),
x = expression(italic(p)*CO[2]~Treatment~"("~mu*atm~")")) +
annotate("text", x=1.5, y=0.2, size = 4, label = "aov(Resp~Treatment + (1|Tank))") +
annotate("text", x=1.5, y=0.16, size = 4, label= paste('DF =',DF,'F =', signif(Fval, digits=3), 'p value =', signif(pval, digits=3), sep=" "))
